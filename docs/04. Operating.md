# Overview

Up until now we have operated in development mode, with only a single Jet instance which is colocated with the code that builds the pipeline.  In this lab we will see how to package a job and deploy it to a pre-existing Jet cluster.   We'll also see how to update a job without missing any events.

We will not add any pipeline stages in this lab. We will just be separating the Jet cluster from the Jet job definition.  We will also introduce a UI that will allow us to visualize the GPS pings.

The resulting system will look like this:

![schematic 4](media/schematic_4.png)



Throughout this lab you will want to make frequent reference to [section 3](https://docs.hazelcast.org/docs/jet/3.2/manual/#work-with-jet) of the Jet Reference Manual.

# Part 1 - Package and Deploy a Jet Job

In this  part, we will bring up a 2 node Jet cluster as well as all of the other parts of the system and then we will deploy our job to the Jet cluster using the `jet.sh` script.



1. First, lets configure the job for fault tolerance. You need to create a "JobConfig" instance and set the processing guarantee and the snapshot frequency.  See the sample code below.

   ```java
   ...
   JobConfig config = new JobConfig();
   config.setProcessingGuarantee(ProcessingGuarantee.AT_LEAST_ONCE);
   config.setSnapshotIntervalMillis(10 * 1000);
   
   String dir = args[0];
   String url = args[1];
   Pipeline pipeline = buildPipeline(dir, url);
   jet.newJob(pipeline, config);
   
   ```

   

2. Now package the job for deployment.  This is mostly done.

   - Review `ingest-pipeling/pom.xml`. Note the following:
     - The shade plugin has been used to package all of the dependencies (e.g. gson) into a single jar.
     - A manifest entry has been added to indicate the main class.
   - Change the scope of the "hazelcast-jet-enterprise" dependency to "provided".  There is no need to package these into the job because it will be running on a Jet node that already the Jet classes.
   - Package the jar.

   ```bash
   $ cd ingest-pipeline
   $ mvn package
   ```

   

3. Start the environment.

   Copy `lab04.yml` to `docker-compose.yml` and start the environment with `docker-compose up -d`.

   This will start the following things:

   - A 2 node Jet cluster
   - IMDG Management Center at http://localhost:8080/hazelcast-mancenter
   - Jet Management Center at http://localhost:8081
   - The "fleetsim-alpha" data generator which writes CSV records to `/opt/project/data/alpha`
   - The "fleetsim-beta" web service at http://localhost:8000/pings
   - The UI, which can be accessed at http://localhost:5006/dashboard

   Take a minute to verify everything is working.  

   Currently, the UI should look like the one below, showing a map of the central US region with no icons on it.

   <img src="media/blank_map.png" alt="blank map" style="zoom:50%;" />

4. Now deploy the job.

   Run at extra copy of the jet container and log in to a shell.

   ```bash
   $ docker-compose run jet-server-1 bash 
   # within the container now 
   
   $ jet.sh -f /opt/project/config/hazelcast-client.xml -v submit /opt/project/ingest-pipeline/target/ingest-pipeline-1.0-SNAPSHOT.jar /opt/project/data/alpha http://fleetsim-beta:8000/pings
   ```

   If all goes well, you should start to see entries in the "vehicles" map within IMDG management center and Jet management center.  Also, each ping should now be depicted on the UI (if you watch long enough you should be able to see the vehicles moving).

   <img src="media/map_with_pings.png" alt="map with pings" style="zoom:50%;" />

As a bonus, pick a VIN from the data and display the corresponding map entry using the "Map Browser" feature of IMDG management center.

![map browser](media/map_browser.png)

# Part 2: Configure Logging

Jet logging is controlled by the underlying IMDG instance. Jet and IMDG can be configured to use any of the  popular logging frameworks.   For details see the [logging configuration section](https://docs.hazelcast.org/docs/3.12.4/manual/html-single/index.html#logging-configuration) of the IMDG manual.  

Soon we will be making an update to the ingest pipeline and we want to observe how Jet behaves during the update.  `BetaStreamSource` already contains log statements (see below).  This will allow us to observe which pings are being processed by the source.  

```java
    public void fillBuffer(SourceBuilder.TimestampedSourceBuffer<Ping> buffer){
        Ping[] pings = poll(highestSequence, 200);

        for(Ping p: pings){
            buffer.add(p, (long) (p.getTime() * 1000.0));
        }

        if (pings.length > 0) {
            highestSequence = pings[pings.length - 1].getSequence();
            logger.fine("Added " + pings.length + " pings. Highest sequence number is: " + highestSequence);
        }

    }

```



We will see that restarts and updates cause the source to "rewind" to the last checkpoint.  First we will configure log4j2 as our logging provider. Currently the system is using the default java logging system. Follow the recipe below to configure log4j2.

1. If the system is still running, stop it using `docker-compose down`

2. Add the dependency for your selected logging framework to the `jet-server` project (not the pipeline).

   ```xml
          <dependency>
               <groupId>org.apache.logging.log4j</groupId>
               <artifactId>log4j-core</artifactId>
               <version>2.12.1</version>
           </dependency>
   ```

   *You will need to repackage the project so that the new dependency will be included.*

   `mvn package`

3. Configure IMDG to use log4j2 by editing `docker-compose.yml` to pass the correct -D options as shown below.  Make sure to make this change for all Jet server instances in the file.

   ```yml
     jet-server-1:
       container_name: jet-server-1
       image: hazelcast/hazelcast-jet-enterprise@sha256:95138f113992b8a98865cc42af59b918b1a9edff4f2d70850f69d8e29996b5cb
       volumes:
         - ".:/opt/project"
       command: >
         java
         -cp /opt/project/jet-server/target/jet-server-1.0-SNAPSHOT.jar
         -Dhazelcast.config=/opt/project/config/hazelcast.xml
         -Dhazelcast.enterprise.license.key=${JET_LICENSE_KEY}
         -Dhazelcast.logging.type=log4j2
         -Dlog4j2.configurationFile=/opt/project/config/log4j2.xml
         com.hazelcast.training.streams.server.Server
   
   ```

   

4. Review `config/log4j2.xml`.  You will see that logging for the ingest job is configured to use the TRACE logging level.  This will allow us to see the output from the "fine" logging statements in `BetaStreamSource.java`.

5. Start the system and deploy the jet job as you did in part 1.  Use `docker-compose logs --follow` to view the logs and verify that you can see the logging output from the jet job.  An example is below.

   ```
   fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:12] "GET /pings?since=599&limit=200 HTTP/1.1" 200 -
   jet-server-2              | 16:01:12.196 [hz._hzInstance_1_dev.jet.blocking.thread-0] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 3 pings. Highest sequence number is: 602
   fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:14] "GET /pings?since=602&limit=200 HTTP/1.1" 200 -
   jet-server-2              | 16:01:14.196 [hz._hzInstance_1_dev.jet.blocking.thread-0] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 3 pings. Highest sequence number is: 605
   fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:16] "GET /pings?since=605&limit=200 HTTP/1.1" 200 -
   fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:18] "GET /pings?since=605&limit=200 HTTP/1.1" 200 -
   jet-server-2              | 16:01:18.198 [hz._hzInstance_1_dev.jet.blocking.thread-0] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 1 pings. Highest sequence number is: 606
   
   ```

_Note: Leave the system running for the next lab._

# Part 3: Updating The Ingest Pipeline

Until now, we have only worked with the GPS information in our data sources but they also contain engine diagnostic codes which will be useful for multiple purposed including detecting when a crash has occurred and predicting required maintenance.

We will now examine how Jet Enterprise allows you to upgrade an existing job without missing events.  

> Now is a good time to review the caveats about restartability of a Jet job.  The sources must be "rewindable",  the pipeline itself must produce deterministic results, and the sinks must be idempotent.  
>
> In our case, the sinks are definitely idempotent because any number of "map.puts" with the same key and value results in the same state as a single put.  The processing is also deterministic.  There are, for example, no external lookup on live data.  
>
> Now consider the sources. Beta is rewindable, when we update the job, the Beta source will be rewound and replayed so we will not miss any events.  Alpha is not rewindable.  This means that, while the job is being updated, some events from Alpha will be missed.  



1. First, use the map browser feature to look at a few VINs and verify that the data does not already contain engine diagnostic codes.

2. Now let's update the code. For this change, all you need to do is add the "obd_codes" field to the Ping java object at `ingest-pipeline/src/main/java/com/hazelcast/training/streams/ingest/Ping.java`.  You just need to uncomment the code.  Once you've updated the Ping object, rebuilt the ingest-pipeline jar.

   ```bash
   $ cd ingest-pipeline
   $ mvn package
   ```

3. Now, use Jet Management to take a snapshot of the running job.  To do this, select the job and press the "export snapshot" button.  Use the "Cancel job and export" option.

4. Now we just need to deploy the new job.  The command is the same except that we add an option to tell Jet to start the job using the snapshot we just created.  

   ```bash
   $ docker-compose -f lab04.yml run jet-server-1 bash
   # inside new container
   $ jet.sh -f /opt/project/config/hazelcast-client.xml -v submit -s my-pipeline /opt/project/ingest-pipeline/target/ingest-pipeline-1.0-SNAPSHOT.jar /opt/project/data/alpha http://fleetsim-beta:8000/pings
   ```

5. You should now be able to verify using the logs that the job resumed and immediately ingested all of the events that occurred while the job was down.

   ```
   fleetsim-beta             | INFO:werkzeug:172.28.0.6 - - [09/Dec/2019 21:24:52] "GET /pings?since=419&limit=200 HTTP/1.1" 200 -
   jet-server-1              | 21:24:52.274 [hz._hzInstance_1_dev.jet.blocking.thread-3] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 163 pings. Highest sequence number is: 769
   ```

6. Now use the map browser in IMDG Management Center to verify that the new entries do indeed have a new field, "obd_codes".

