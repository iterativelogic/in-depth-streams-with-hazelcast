# Overview

Up until now we have operated in development mode, with only a single Jet instance which is colocated with the code that builds the pipeline.  In this lab we will see how to package a job and deploy it to a pre-existing Jet cluster.   We'll also see how to update a job without missing any events.

We will not add any pipeline stages in this lab. We will just be separating the Jet cluster from the Jet job definition.  We will also introduce a UI that will allow us to visualize the GPS pings.

The resulting system will look like this:

![schematic 4](media/schematic_4.png)



Throughout this lab you will want to make frequent reference to [section 3](https://docs.hazelcast.org/docs/jet/3.2/manual/#work-with-jet) of the Jet Reference Manual.

Expected Time: 1 hr 20 min.

# Part 1 - Configure Enterprise Features and Logging

In this  part, we will bring up a 2 node Jet cluster as well as all of the other parts of the system and then we will deploy our job to the Jet cluster using the `jet.sh` script.  First , we will configure logging, fault tolerance and hot restart for Jet.

Jet logging is controlled by the underlying IMDG instance. Jet and IMDG can be configured to use any of the  popular logging frameworks.   For details see the [logging configuration section](https://docs.hazelcast.org/docs/3.12.4/manual/html-single/index.html#logging-configuration) of the IMDG manual.  

Soon we will be making an update to the ingest pipeline and we want to observe how Jet behaves during the update. 

1. Update  `BetaStreamSource` with logging as as shown below.  This will be used later to observe how Jet handles restarts.

```java
    public void fillBuffer(SourceBuilder.TimestampedSourceBuffer<Ping> buffer){
        Ping[] pings = poll(highestSequence, 200);

        for(Ping p: pings){
            buffer.add(p, (long) (p.getTime() * 1000.0));
        }

      	// add this to log the highest sequence number
        if (pings.length > 0) {
            highestSequence = pings[pings.length - 1].getSequence();
            logger.fine("Added " + pings.length + " pings. Highest sequence number is: " + highestSequence);
        }

    }

```



2. Copy `lab04.yml` to `docker-compose.yml`

3. Configure Logging	
   1. If the system is still running, stop it using `docker-compose down`

   2. Add the dependency for your selected logging framework to the `jet-server` project (not the pipeline).

   ```XML
   <dependency>
       <groupId>org.apache.logging.log4j</groupId>
       <artifactId>log4j-core</artifactId>
       <version>2.12.1</version>
   </dependency>
   ```

   *You will need to repackage the project so that the new dependency will be included.*

   `mvn package`

4. Configure IMDG to use log4j2 by editing `docker-compose.yml` to pass the correct -D options as shown below.  Make sure to make this change for all Jet server instances in the file.

   ```yml
   jet-server-1:
    container_name: jet-server-1
    image: hazelcast/hazelcast-jet-enterprise@sha256:95138f113992b8a98865cc42af59b918b1a9edff4f2d70850f69d8e29996b5cb
    volumes:
      - ".:/opt/project"
    command: >
      java
      -cp /opt/project/jet-server/target/jet-server-1.0-SNAPSHOT.jar
      -Dhazelcast.config=/opt/project/config/hazelcast.xml
      -Dhazelcast.enterprise.license.key=${JET_LICENSE_KEY}
      -Dhazelcast.logging.type=log4j2
      -Dlog4j2.configurationFile=/opt/project/config/log4j2.xml
      com.hazelcast.training.streams.server.Server
   ```

5. Review `config/log4j2.xml`.  Set the logging level to "trace" for "com.hazelcast.training" `BetaStreamSource.java`.  

6. Now, configure hot restart persistence. This configuration must be done in 2 places: the Jet configuration file and the IMDG configuration file.  Note that in `docker-compose.yml` we are using "-Dhazelcast.jet.config" to explicitly point Jet to the configuration file at `/opt/project/config/hazelcast-jet.xml`.

   Edit `hazelcast-jet.xml` to enable lossless restart.  	

```xml
<hazelcast-jet xsi:schemaLocation="http://www.hazelcast.com/schema/jet-config hazelcast-jet-config-3.0.xsd"
               xmlns="http://www.hazelcast.com/schema/jet-config"
               xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
    <instance>
        <lossless-restart-enabled>true</lossless-restart-enabled>
    </instance>
</hazelcast-jet>
```



Then, in the IMDG configuration file, `hazelcast.xml`, configure the location of the hot restart disk stores as shown below.

```xml
...
    <hot-restart-persistence enabled="true">
     <base-dir>/opt/project/host-restart</base-dir>
    </hot-restart-persistence>
...
```

7. Start the environment with `docker-compose up -d`.

This will start the following things:

- A 2 node Jet cluster
- IMDG Management Center at http://localhost:8080/hazelcast-mancenter
- Jet Management Center at http://localhost:8081
- The "fleetsim-alpha" data generator which writes CSV records to `/opt/project/data/alpha`
- The "fleetsim-beta" web service at http://localhost:8000/pings
- The UI, which can be accessed at http://localhost:5006/dashboard

Take a minute to verify everything is working.  

Currently, the UI should look like the one below, showing a map of the central US region with no icons on it.

<img src="media/blank_map.png" alt="blank map" style="zoom:50%;" />

  # Part 2 - Package the Job and Deploy It

Jobs that are deployed to a standalone cluster have a few small differences.  This section describes how to set up such a job and deploy it.

   1. Configure the job for fault tolerance. _This must be done per job in the code_.  Edit the "main" method of `ingest-pipeline/src/main/java/com/hazelcast/training/`You need to create a "JobConfig" instance and set the processing guarantee and the snapshot frequency.  See the sample code below.

      ```java
      ...
      JobConfig config = new JobConfig();
      config.setProcessingGuarantee(ProcessingGuarantee.AT_LEAST_ONCE);
      config.setSnapshotIntervalMillis(10 * 1000);
      
      String dir = args[0];
      String url = args[1];
      Pipeline pipeline = buildPipeline(dir, url);
      jet.newJob(pipeline, config);
      ```

   2. Package the job for deployment. 

      This is mostly done for you. Review `ingest-pipeling/pom.xml`. Note the following:

      - The shade plugin has been used to package all of the dependencies (e.g. gson) into a single jar.
      - A manifest entry has been added to indicate the main class.

      In `ingest-pipeline/pom.xml` change the scope of the "hazelcast-jet-enterprise" dependency to "provided".  There is no need to package these into the job because it will be running on a Jet node that already the Jet classes.

      ```xml
           <dependency>
               <groupId>com.hazelcast.jet</groupId>
               <artifactId>hazelcast-jet-enterprise</artifactId>
               <scope>provided</scope>
           </dependency>
      ```

   3. Package the jar.

      ```bash
      $ mvn package
      ```

      

   4. Deploy the job! You will find a new "admin-server" service in `docker-compose.yml`.  This is just a server with all of the Jet software on it that can be used to deploy your jet job.  In a real life situation this could be any server with the jet software installed and network connectivity to the jet cluster.

      ```bash
$ docker-compose run admin-server bash 
      # within the container now 
      
      $ jet.sh -f /opt/project/config/hazelcast-client.xml -v submit /opt/project/ingest-pipeline/target/ingest-pipeline-1.0-SNAPSHOT.jar /opt/project/data/alpha http://fleetsim-beta:8000/pings
      ```
      
      If all goes well, you should start to see entries in the "vehicles" map within IMDG management center and Jet management center.  Refresh the UI page.  Each ping should now be depicted on the UI (if you watch long enough you should be able to see the vehicles moving).

   <img src="media/map_with_pings.png" alt="map with pings" style="zoom:50%;" />

   5. As a bonus, pick a VIN from the data and display the corresponding map entry using the "Map Browser" feature of IMDG management center.

      ![map browser](media/map_browser.png)



6.  Use `docker-compose logs --follow` to view the logs and verify that you can see the logging output from the jet job.  An example is below.

   ```
fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:12] "GET /pings?since=599&limit=200 HTTP/1.1" 200 -
jet-server-2              | 16:01:12.196 [hz._hzInstance_1_dev.jet.blocking.thread-0] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 3 pings. Highest sequence number is: 602
fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:14] "GET /pings?since=602&limit=200 HTTP/1.1" 200 -
jet-server-2              | 16:01:14.196 [hz._hzInstance_1_dev.jet.blocking.thread-0] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 3 pings. Highest sequence number is: 605
fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:16] "GET /pings?since=605&limit=200 HTTP/1.1" 200 -
fleetsim-beta             | INFO:werkzeug:172.24.0.6 - - [09/Dec/2019 16:01:18] "GET /pings?since=605&limit=200 HTTP/1.1" 200 -
jet-server-2              | 16:01:18.198 [hz._hzInstance_1_dev.jet.blocking.thread-0] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 1 pings. Highest sequence number is: 606

   ```

_Note: Leave the system running for the next lab._

# Part 3: Scale Up and Down, Test Fault Tolerance

By default, when you add nodes to a cluster, any job with a configured processing guarantee will spread out to use all available members.  Try it now. _Do not stop the system before doing this lab._

Add another jet server to `docker-compose.yml`.  Be sure you change the service name and the container name to "jet-server-3" and update the IP address to 192.168.1.103.  In one window, watch the logs (`docker-compose logs --follow`), in another window, bring up the 3rd member with (`docker-compose up -d`).  

Watch the logs to see what happens.  After about 30 seconds you should see the job restart.  In the Jet Management Center, if you select the job, you will be able to see the number of nodes in use go from 2 to 3.

Now, using the logs, determine which server is running the "Beta" source.  This will be the one that produces log messages like those below.

```
jet-server-3              | 19:43:02.825 [hz._hzInstance_1_dev.jet.blocking.thread-0] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 3 pings. Highest sequence number is: 1037
```

Now, simulate a failure of that server as follows.  _Be sure to use the correct container name, yours may not be jet-server-3_ . `docker-compose kill jet-server-3`.

After 20-30 seconds, you should see that the job is restarted and the "Beta" source will begin processing events where it left off .

Bring the system back to full capacity by running `docker-compose up -d`

# Part 4: Update a Deployed Job Without Missing Events - Case 1: No Change to Classes on the Server Classpath

You may have noticed that the classes defined in the ingest pipeline did not have to be installed on the server class path and no servers had to be restarted.  It just worked!  

In this lab, we will update and redeploy a job.  Some classes must be deployed to the server class path.  This includes classes that are shared between jobs (e.g. domain classes) and Hazelcast IMDG server side code like EntryProcessors and Aggregators.  In this lab, we will make a change that does _not_ involve any of these things.  In this case, making a change is as simple as cancelling the job and re-deploying it.

> Now is a good time to review the caveats about restartability of a Jet job.  The sources must be "rewindable",  the pipeline itself must produce deterministic results, and the sinks must be idempotent.  
>
> In our case, the sinks are definitely idempotent because any number of "map.puts" with the same key and value results in the same state as a single put.  The processing is also deterministic.  There are, for example, no external lookups on live data.  
>
> Now consider the sources. Beta is rewindable.  When we update the job, the Beta source will be  replayed from the last snapshot so we will not miss any events.  Alpha is not rewindable.  This means that, while the job is being updated,  events from Alpha will be missed.  

1. First, use the map browser feature to look at a few VINs and verify that the data does not already contain engine diagnostic codes.

2. Now  update the code. For this change, all you need to do is add the "obd_codes" field to the Ping java object at `common/src/main/java/com/hazelcast/training/streams/model/Ping.java`.   Once you've updated the Ping object, rebuilt the ingest-pipeline jar.  Note: since the ingest-pipeline project references the common project where Ping is, you will need to rebuild that as well.  The best way to do that is to run "mvn install" at the top level of the project.

   ```bash
   $ mvn install
   ```

3. Now, use Jet Management to take a snapshot of the running job.  To do this, select the job and press the "export snapshot" button.  Use the "Cancel job and export" option.

4. Now we just need to deploy the new job.  The command is the same except that we add the "-s"  option to tell Jet to start the job using the snapshot we just created.  

   ```bash
   $ docker-compose  run admin-server bash
   # inside new container
   $ jet.sh -f /opt/project/config/hazelcast-client.xml -v submit -s my-pipeline /opt/project/ingest-pipeline/target/ingest-pipeline-1.0-SNAPSHOT.jar /opt/project/data/alpha http://fleetsim-beta:8000/pings
   ```

5. You should now be able to verify using the logs that the job resumed and immediately ingested all of the events that occurred while the job was down.

   ```
   fleetsim-beta             | INFO:werkzeug:172.28.0.6 - - [09/Dec/2019 21:24:52] "GET /pings?since=419&limit=200 HTTP/1.1" 200 -
   jet-server-1              | 21:24:52.274 [hz._hzInstance_1_dev.jet.blocking.thread-3] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 163 pings. Highest sequence number is: 769
   ```

6. Now use the map browser in IMDG Management Center to verify that the new entries do indeed have a new field, "obd_codes".

# 

# Part : Test Hot Restart

Hot restart persists the running pipelines and snapshots of all stateful processors.  When the system is started after a complete shutdown it will restore itself from the snapshot and resume processing.

Observe the logs while stoping and starting the cluster using the following procedure.

1. Shut down the cluster using the button in Jet Management center.  _Do not use docker-compose down because this will shut down the other systems as well._
2. Use `docker-compose up -d` to bring up the Jet cluster. Docker compose automatically detects what is already running and starts only what is not running.

You should see that after startup, the ingest pipeline automatically deploys itself and resumes processing.  This is the power of hot restart!

Until now, we have only worked with the GPS information in our data sources but they also contain engine diagnostic codes which will be useful for multiple purposed including detecting when a crash has occurred and predicting required maintenance.

We will now examine how Jet Enterprise allows you to upgrade an existing job without missing events.  

> Now is a good time to review the caveats about restartability of a Jet job.  The sources must be "rewindable",  the pipeline itself must produce deterministic results, and the sinks must be idempotent.  
>
> In our case, the sinks are definitely idempotent because any number of "map.puts" with the same key and value results in the same state as a single put.  The processing is also deterministic.  There are, for example, no external lookups on live data.  
>
> Now consider the sources. Beta is rewindable.  When we update the job, the Beta source will be  replayed from the last snapshot so we will not miss any events.  Alpha is not rewindable.  This means that, while the job is being updated,  events from Alpha will be missed.  

1. First, use the map browser feature to look at a few VINs and verify that the data does not already contain engine diagnostic codes.

2. Now  update the code. For this change, all you need to do is add the "obd_codes" field to the Ping java object at `common/src/main/java/com/hazelcast/training/streams/model/Ping.java`.   Once you've updated the Ping object, rebuilt the ingest-pipeline jar.  Note: since the ingest-pipeline project references the common project where Ping is, you will need to rebuild that as well.  The best way to do that is to run "mvn install" at the top level of the project.

   ```bash
   $ mvn install
   ```

3. Now, use Jet Management to take a snapshot of the running job.  To do this, select the job and press the "export snapshot" button.  Use the "Cancel job and export" option.

4. Now we just need to deploy the new job.  The command is the same except that we add the "-s"  option to tell Jet to start the job using the snapshot we just created.  

   ```bash
   $ docker-compose  run admin-server bash
   # inside new container
   $ jet.sh -f /opt/project/config/hazelcast-client.xml -v submit -s my-pipeline /opt/project/ingest-pipeline/target/ingest-pipeline-1.0-SNAPSHOT.jar /opt/project/data/alpha http://fleetsim-beta:8000/pings
   ```

5. You should now be able to verify using the logs that the job resumed and immediately ingested all of the events that occurred while the job was down.

   ```
   fleetsim-beta             | INFO:werkzeug:172.28.0.6 - - [09/Dec/2019 21:24:52] "GET /pings?since=419&limit=200 HTTP/1.1" 200 -
   jet-server-1              | 21:24:52.274 [hz._hzInstance_1_dev.jet.blocking.thread-3] DEBUG com.hazelcast.training.streams.ingest.BetaStreamSource - Added 163 pings. Highest sequence number is: 769
   ```

6. Now use the map browser in IMDG Management Center to verify that the new entries do indeed have a 

# Recap

After this lab, we now have a fault tolerant and persistent job deployed to a 3 node Jet cluster!

